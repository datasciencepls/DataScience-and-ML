{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: We don't split data into training and testing. We just learn how to write gradient descent from scratch\n",
    "\n",
    "We'll be using all the data points to optimally find coefficients for data having single feature only i.e finding m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single iteration of gradient decsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(points, learning_rate, m, c):\n",
    "    m_slope=0\n",
    "    c_slope=0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        m_slope += (-2/M)*(y-m*x-c)*x\n",
    "        c_slope += (-2/M)*(y-m*x-c)\n",
    "    new_m = m - learning_rate*m_slope\n",
    "    new_c = c - learning_rate*c_slope\n",
    "    return new_m, new_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points, m, c):\n",
    "    total_cost = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        total_cost += (1/M)*((y-m*x-c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(points, learning_rate, num_iterations):\n",
    "    # Choose any value for m and c\n",
    "    m = 0\n",
    "    c = 0\n",
    "    for i in range(num_iterations):\n",
    "        m,c = step_gradient(points, learning_rate, m, c)\n",
    "        \n",
    "        # After every iteration if our cost is incresing then it means we need to reduce  learning_rate\n",
    "        print(i+1, \"Cost: \", cost(points, m, c))\n",
    "    \n",
    "    return m,c # new m and c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    data = np.loadtxt('Sampledata.csv', delimiter=',', skiprows=1) # skip bcz 1st row is of headers which can't be converted into float as they are in string\n",
    "    \n",
    "    #learning_rate = 0.001 # cost increases. So we need to reduce learning_rate\n",
    "    learning_rate = 0.0000001\n",
    "    num_iterations = 100\n",
    "    \n",
    "    m,c = gd(data, learning_rate, num_iterations)\n",
    "    print(m,c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Cost:  1.159787676120075\n",
      "2 Cost:  0.15559270934140526\n",
      "3 Cost:  0.05478820205617395\n",
      "4 Cost:  0.044669102652737575\n",
      "5 Cost:  0.04365331302666903\n",
      "6 Cost:  0.04355134460776471\n",
      "7 Cost:  0.04354110867068131\n",
      "8 Cost:  0.04354008115221979\n",
      "9 Cost:  0.04353997800614878\n",
      "10 Cost:  0.0435399676517233\n",
      "11 Cost:  0.04353996661203888\n",
      "12 Cost:  0.04353996650739989\n",
      "13 Cost:  0.043539966496623915\n",
      "14 Cost:  0.043539966495270234\n",
      "15 Cost:  0.043539966494862414\n",
      "16 Cost:  0.043539966494549553\n",
      "17 Cost:  0.04353996649424618\n",
      "18 Cost:  0.04353996649394378\n",
      "19 Cost:  0.0435399664936415\n",
      "20 Cost:  0.043539966493339216\n",
      "21 Cost:  0.043539966493036875\n",
      "22 Cost:  0.043539966492734575\n",
      "23 Cost:  0.04353996649243232\n",
      "24 Cost:  0.04353996649212998\n",
      "25 Cost:  0.043539966491827696\n",
      "26 Cost:  0.043539966491525375\n",
      "27 Cost:  0.0435399664912231\n",
      "28 Cost:  0.04353996649092083\n",
      "29 Cost:  0.04353996649061853\n",
      "30 Cost:  0.04353996649031621\n",
      "31 Cost:  0.043539966490013925\n",
      "32 Cost:  0.04353996648971166\n",
      "33 Cost:  0.04353996648940935\n",
      "34 Cost:  0.0435399664891071\n",
      "35 Cost:  0.043539966488804774\n",
      "36 Cost:  0.04353996648850249\n",
      "37 Cost:  0.04353996648820019\n",
      "38 Cost:  0.04353996648789789\n",
      "39 Cost:  0.0435399664875956\n",
      "40 Cost:  0.04353996648729331\n",
      "41 Cost:  0.04353996648699102\n",
      "42 Cost:  0.043539966486688716\n",
      "43 Cost:  0.04353996648638643\n",
      "44 Cost:  0.04353996648608413\n",
      "45 Cost:  0.04353996648578183\n",
      "46 Cost:  0.04353996648547955\n",
      "47 Cost:  0.04353996648517723\n",
      "48 Cost:  0.04353996648487495\n",
      "49 Cost:  0.04353996648457267\n",
      "50 Cost:  0.043539966484270366\n",
      "51 Cost:  0.04353996648396811\n",
      "52 Cost:  0.04353996648366575\n",
      "53 Cost:  0.0435399664833635\n",
      "54 Cost:  0.04353996648306119\n",
      "55 Cost:  0.0435399664827589\n",
      "56 Cost:  0.0435399664824566\n",
      "57 Cost:  0.043539966482154316\n",
      "58 Cost:  0.04353996648185203\n",
      "59 Cost:  0.04353996648154973\n",
      "60 Cost:  0.04353996648124744\n",
      "61 Cost:  0.04353996648094512\n",
      "62 Cost:  0.043539966480642844\n",
      "63 Cost:  0.04353996648034056\n",
      "64 Cost:  0.04353996648003823\n",
      "65 Cost:  0.04353996647973597\n",
      "66 Cost:  0.04353996647943367\n",
      "67 Cost:  0.043539966479131366\n",
      "68 Cost:  0.04353996647882907\n",
      "69 Cost:  0.04353996647852681\n",
      "70 Cost:  0.043539966478224466\n",
      "71 Cost:  0.0435399664779222\n",
      "72 Cost:  0.0435399664776199\n",
      "73 Cost:  0.04353996647731762\n",
      "74 Cost:  0.04353996647701534\n",
      "75 Cost:  0.043539966476713016\n",
      "76 Cost:  0.04353996647641074\n",
      "77 Cost:  0.043539966476108416\n",
      "78 Cost:  0.043539966475806144\n",
      "79 Cost:  0.04353996647550387\n",
      "80 Cost:  0.043539966475201544\n",
      "81 Cost:  0.04353996647489926\n",
      "82 Cost:  0.043539966474596965\n",
      "83 Cost:  0.043539966474294665\n",
      "84 Cost:  0.0435399664739924\n",
      "85 Cost:  0.04353996647369011\n",
      "86 Cost:  0.0435399664733878\n",
      "87 Cost:  0.04353996647308551\n",
      "88 Cost:  0.043539966472783215\n",
      "89 Cost:  0.04353996647248091\n",
      "90 Cost:  0.04353996647217862\n",
      "91 Cost:  0.04353996647187635\n",
      "92 Cost:  0.043539966471574036\n",
      "93 Cost:  0.043539966471271736\n",
      "94 Cost:  0.04353996647096945\n",
      "95 Cost:  0.04353996647066717\n",
      "96 Cost:  0.043539966470364865\n",
      "97 Cost:  0.04353996647006257\n",
      "98 Cost:  0.043539966469760286\n",
      "99 Cost:  0.043539966469457986\n",
      "100 Cost:  0.04353996646915568\n",
      "0.0018042676141872154 9.920738032766797e-07\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With some changes we can actually write gradient descent for data having n features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
